{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8LBm3+2HvalP8HmkiGQ5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeshalCS/smartathon/blob/main/Smartathone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual Pollution Detection. \n",
        "\n",
        "Since visual pollution is a relatively recent issue compared to other forms of environmental contamination, study is needed to define, formalize, measure, and evaluate it from many angles. This competition aims to establish a new field of automated visual pollution classification, utilizing the technological prowess of the twenty-first century for environmental management applications. By training and testing approaches to convolutional neural networks we expect competitors to simulate the human learning experience in the context of picture identification for the classification of visual pollutants. Additionally this will be useful for the development of a \"visual pollution score/index\" for urban areas that might produce a new \"metric\" or \"indicator\" in the discipline of urban environmental management. In this competition, you will build and optimize algorithms based on a large-scale dataset. This dataset features the raw sensor camera inputs as perceived by a fleet of multiple vehicles in a restricted geographic area in KSA If successful, youâ€™ll make a significant contribution towards stimulating further development city planning and empowering communities around the world\n"
      ],
      "metadata": {
        "id": "dU8lNrlVDDYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset:"
      ],
      "metadata": {
        "id": "RIya3pecDL2s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJJWEyUTCyP2"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "train_df = pd.read_csv(\"../dataset/train.csv\")\n",
        "test_df = pd.read_csv(\"../dataset/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# store images and labels:"
      ],
      "metadata": {
        "id": "2kx41cxaDesJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a list to store the images and labels\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "# Loop through the train dataset\n",
        "for index, row in train_df.iterrows():\n",
        "    # Read the image\n",
        "    img = image.load_img(\"../dataset/images/\" + row[\"image_path\"], target_size=(224,224))\n",
        "    # Convert the image to array\n",
        "    img = image.img_to_array(img)\n",
        "    # Append the image to the X list\n",
        "    X.append(img)\n",
        "    # Append the label to the Y list\n",
        "    Y.append(row[\"class\"])"
      ],
      "metadata": {
        "id": "bx-2sITFDCd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the X and Y lists to numpy arrays\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "metadata": {
        "id": "T7f4wfvIDrEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the labels\n",
        "Y = to_categorical(Y)"
      ],
      "metadata": {
        "id": "Jxs2DN0rDtTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data:"
      ],
      "metadata": {
        "id": "pS7tQm_jD2d9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
      ],
      "metadata": {
        "id": "0cHZllUcDtWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# build the model:"
      ],
      "metadata": {
        "id": "beiYvQg5D7OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "input_shape = (224, 224, 3)\n",
        "input_tensor = Input(shape=input_shape)\n",
        "x = input_tensor\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output_tensor = Dense(11, activation='softmax')(x)\n",
        "model = Model(input_tensor, output_tensor)"
      ],
      "metadata": {
        "id": "usa77n-_DtZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3O8JsciDEFuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model:"
      ],
      "metadata": {
        "id": "M9Rh1WvUELCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, Y_train, batch_size=32, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "id": "h2yf_kH2EFrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# if you need more train:\n",
        "\n"
      ],
      "metadata": {
        "id": "lZoitXZSEXtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (More) Train the model\n",
        "model.fit(X_train, Y_train, batch_size=32, epochs=5, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "id": "H2eLvXlPEFld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test the model:"
      ],
      "metadata": {
        "id": "H4O__XjDExE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on the test dataset\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "# Test the model on new unseen data\n",
        "img = image.load_img(\"../images/f1d7b69f389786365bfc927405f16b8b.jpg\", target_size=(224,224))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis=0)\n",
        "prediction = model.predict(img)"
      ],
      "metadata": {
        "id": "OVOSn6GPEFiN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}